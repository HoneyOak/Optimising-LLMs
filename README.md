# Optimizing LLMs
This project shows the steps to optimise a Large Language Model (LLM) employing DSPy in order to better suit a specifc question-answering domain.
dspy does:
-Prompt omptimisation through MIPROv2
-Retrieval-Augmented Generation (RAG) to provide answers based on context
-Local embeddings to make retrieving documents efficent
-Testing and evaulation on a specific dataset 
to improve llm performance

## prompt optimization
dspy optimization info
and how it works - tests llms on questions
what it does 

## Code usage
pip install


## steps/walkthrough
embeddings
read context
rag
trainset
optimizing using mipro v2

created optimized_program.json

## testing
optimized tester
load optimized.json
rag
testing prompts

## next steps
improving questions
see optimized_program.json for changes
